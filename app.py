import os
import json
import sqlite3
import pandas as pd
import re
from bs4 import BeautifulSoup
from arelle import Cntlr

# ğŸ”¹ Initialize Arelle
cntlr = Cntlr.Cntlr()

# ğŸ”¹ File Path (×™×© ×œ×”×–×™×Ÿ ×§×•×‘×¥ XBRL/SEC × ×›×•×Ÿ)
file_path = "/Users/elmaliahmac/Documents/HippoDashBoard/py/0001300514-25-000040.txt"
tags_json_path = "/Users/elmaliahmac/Documents/HippoDashBoard/py/structured_tags.json"
db_path = "/Users/elmaliahmac/Documents/HippoDashBoard/py/xbrl_data.db"
all_tags_csv_path = "/Users/elmaliahmac/Documents/HippoDashBoard/py/all_xbrl_tags.csv"

# ğŸ”¹ Load XBRL File
model_xbrl = cntlr.modelManager.load(file_path)

# ğŸ”¹ ×©×œ×™×¤×ª × ×ª×•× ×™ ×—×‘×¨×” (Ticker, CIK, ×“×•×— ×•×©× ×”)
ticker = None
name = None
report_type = None
fiscal_year = None

for fact in model_xbrl.facts:
    tag = fact.concept.qname.localName if fact.concept else fact.qname.localName
    value = fact.value.strip() if fact.value else None

    if tag == "TradingSymbol":  # ×©×œ×™×¤×ª Ticker
        name = value
        ticker = value
    elif tag == "DocumentType":  # ×¡×•×’ ×”×“×•×— (10-K, 10-Q, ×•×›×•')
        report_type = value
    elif tag == "DocumentFiscalYearFocus":  # ×©× ×ª ×”×“×•×—
        fiscal_year = value
    elif tag == "DocumentPeriodEndDate" and not fiscal_year:  # ×—×œ×•×¤×” ×× ××™×Ÿ DocumentFiscalYearFocus
        fiscal_year = value[:4]  # ×©×•×œ×¤×™× ×¨×§ ××ª ×”×©× ×” (YYYY-MM-DD â†’ YYYY)

# ğŸ”¹ ×©×™××•×© ×‘-CIK ×× ××™×Ÿ Ticker
company_id = ticker if ticker else name if name else "Unknown" 

# ğŸ”¹ ×˜×™×¤×•×œ ×‘××§×¨×” ×©××™×Ÿ × ×ª×•× ×™×
if not report_type:
    report_type = "Unknown_Report"
if not fiscal_year:
    fiscal_year = "Unknown_Year"

# ğŸ”¹ ×§×•×‘×¥ CSV ×™×™×—×•×“×™ ×œ×›×œ ×—×‘×¨×” ×•×“×•×—
csv_output_path = f"/Users/elmaliahmac/Documents/HippoDashBoard/py/{company_id}_{report_type}_{fiscal_year}.csv"

# ğŸ”¹ ×”×ª×—×‘×¨×•×ª ×œ××¡×“ ×”× ×ª×•× ×™× (×œ×œ× ××—×™×§×”)
conn = sqlite3.connect(db_path)
cursor = conn.cursor()

# ğŸ”¹ ×™×¦×™×¨×ª ×˜×‘×œ×ª × ×ª×•× ×™× ×¢× ××–×”×” ×—×‘×¨×” ×•×“×•×— (×× ×œ× ×§×™×™××ª)
cursor.execute("""
CREATE TABLE IF NOT EXISTS xbrl_data (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    company_id TEXT,
    report_type TEXT,
    fiscal_year TEXT,
    tag TEXT,
    regulatory_name TEXT,
    clean_value TEXT,
    start_date TEXT,
    end_date TEXT,
    instant TEXT,
    category TEXT,
    sub_category TEXT,
    type TEXT,
    risk_level TEXT,
    usage TEXT
);
""")

# ğŸ”¹ ×˜×¢×™× ×ª ××˜×-×“××˜×”
with open(tags_json_path, "r", encoding="utf-8") as json_file:
    tags_data = json.load(json_file)

# ğŸ”¹ × ×™×§×•×™ HTML ××”× ×ª×•× ×™×
def clean_html(raw_html):
    soup = BeautifulSoup(raw_html, "html.parser")
    
    for table in soup.find_all("table"):
        table.decompose()
    
    for tag in soup.find_all(["style", "script", "meta", "link"]):
        tag.decompose()
    
    text = soup.get_text(separator="\n")
    text = re.sub(r'\n\s*\n+', '\n\n', text)
    text = re.sub(r'\t+', ' ', text)
    text = re.sub(r' {2,}', ' ', text)
    text = text.strip()

    return text

# ğŸ”¹ ××—×¡×•×Ÿ × ×ª×•× ×™×
all_data = []
all_tags = set()

# ğŸ”¹ ×¢×™×‘×•×“ ×”× ×ª×•× ×™× ××”×“×•×—
for fact in model_xbrl.facts:
    tag = fact.concept.qname.localName if fact.concept else fact.qname.localName
    value = fact.value if fact.value else "N/A"
    all_tags.add(tag)

    if "ixTransformValueError" in value:
        value = value.replace("ixTransformValueError", "").strip()

    meta = tags_data.get("Metadata", {}).get(tag, {})

    regulatory_name = meta.get("RegulatoryName", "Unknown")
    category = meta.get("Category", "Unknown")
    sub_category = meta.get("SubCategory", "Unknown")
    data_type = meta.get("Type", "Unknown")
    risk_level = meta.get("RiskLevel", "Unknown")
    usage = ", ".join(meta.get("Usage", ["Unknown"]))

    context = fact.context
    start_date = str(context.startDatetime if context.isStartEndPeriod else "NULL")
    end_date = str(context.endDatetime if context.isStartEndPeriod else "NULL")
    instant = str(context.instantDatetime if context.isInstantPeriod else "NULL")
    
    clean_value = clean_html(value)
    
    all_data.append((
        company_id,
        report_type,
        fiscal_year,
        tag,
        regulatory_name,
        clean_value,
        start_date,
        end_date,
        instant,
        category,
        sub_category,
        data_type,
        risk_level,
        usage
    ))

# ğŸ”¹ ×©××™×¨×ª × ×ª×•× ×™× ×œ×§×•×‘×¥ CSV

df_all = pd.DataFrame(all_data, columns=[
    "CompanyID", "ReportType", "FiscalYear", "Tag", "RegulatoryName", "CleanValue",
    "StartDate", "EndDate", "Instant", "Category", "SubCategory", "Type", "RiskLevel", "Usage"
])
df_all.to_csv(csv_output_path, index=False)

# ğŸ”¹ ×©××™×¨×ª ×¨×©×™××ª ×›×œ ×”×ª×’×™×
if os.path.exists(all_tags_csv_path):
    df_existing_tags = pd.read_csv(all_tags_csv_path)
    all_tags.update(df_existing_tags["Tag"].tolist())

df_tags = pd.DataFrame(sorted(all_tags), columns=["Tag"])
df_tags.to_csv(all_tags_csv_path, index=False)

# ğŸ”¹ ×©××™×¨×ª × ×ª×•× ×™× ×œ××¡×“ × ×ª×•× ×™×
cursor.executemany("""
INSERT INTO xbrl_data (company_id, report_type, fiscal_year, tag, regulatory_name, clean_value, start_date, end_date, instant, category, sub_category, type, risk_level, usage)
VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?);
""", all_data)

conn.commit()
conn.close()

print(f"âœ… Data for {company_id} ({report_type} {fiscal_year}) saved to database.")
print(f"âœ… Extracted data saved to: {csv_output_path}")
print(f"âœ… All tags saved to: {all_tags_csv_path}")
